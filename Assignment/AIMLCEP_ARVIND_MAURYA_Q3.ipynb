{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIMLCEP_ARVIND_MAURYA_Q3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arvind-maurya/MachineLearning/blob/master/Assignment/AIMLCEP_ARVIND_MAURYA_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202Op-BXgfwH"
      },
      "source": [
        "#First, we import the required packages\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd #the pandas library is useful for data processing \n",
        "import matplotlib.pyplot as plt #the matplotlib library is useful for plotting purposes\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q3.a Shuffle and break the data into 80% train and 20% test data**"
      ],
      "metadata": {
        "id": "rFNDf7-1Ljh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the data from the csv file \n",
        "sample_data = pd.read_csv('https://github.com/arvind-maurya/MachineLearning/blob/master/Assignment/Q3/Q3_data.csv?raw=true', index_col=False)\n",
        "#print the data \n",
        "sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-LPtjcEF7gN8",
        "outputId": "c1ed9eff-7fbd-4282-8de3-a2d187e47ecd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7b5d7fb-08e6-4b45-a706-b655a84fe530\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>feature0</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>feature35</th>\n",
              "      <th>feature36</th>\n",
              "      <th>feature37</th>\n",
              "      <th>feature38</th>\n",
              "      <th>...</th>\n",
              "      <th>feature744</th>\n",
              "      <th>feature745</th>\n",
              "      <th>feature746</th>\n",
              "      <th>feature747</th>\n",
              "      <th>feature748</th>\n",
              "      <th>feature749</th>\n",
              "      <th>feature750</th>\n",
              "      <th>feature751</th>\n",
              "      <th>feature752</th>\n",
              "      <th>feature753</th>\n",
              "      <th>feature754</th>\n",
              "      <th>feature755</th>\n",
              "      <th>feature756</th>\n",
              "      <th>feature757</th>\n",
              "      <th>feature758</th>\n",
              "      <th>feature759</th>\n",
              "      <th>feature760</th>\n",
              "      <th>feature761</th>\n",
              "      <th>feature762</th>\n",
              "      <th>feature763</th>\n",
              "      <th>feature764</th>\n",
              "      <th>feature765</th>\n",
              "      <th>feature766</th>\n",
              "      <th>feature767</th>\n",
              "      <th>feature768</th>\n",
              "      <th>feature769</th>\n",
              "      <th>feature770</th>\n",
              "      <th>feature771</th>\n",
              "      <th>feature772</th>\n",
              "      <th>feature773</th>\n",
              "      <th>feature774</th>\n",
              "      <th>feature775</th>\n",
              "      <th>feature776</th>\n",
              "      <th>feature777</th>\n",
              "      <th>feature778</th>\n",
              "      <th>feature779</th>\n",
              "      <th>feature780</th>\n",
              "      <th>feature781</th>\n",
              "      <th>feature782</th>\n",
              "      <th>feature783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23995</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23997</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>147</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23998</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23999</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24000 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7b5d7fb-08e6-4b45-a706-b655a84fe530')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7b5d7fb-08e6-4b45-a706-b655a84fe530 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7b5d7fb-08e6-4b45-a706-b655a84fe530');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label  feature0  feature1  ...  feature781  feature782  feature783\n",
              "0          1         0         0  ...           0           0           0\n",
              "1          2         0         0  ...           0           0           0\n",
              "2          3         0         0  ...           0           0           0\n",
              "3          4         0         0  ...           0           0           0\n",
              "4          1         0         0  ...           0           0           0\n",
              "...      ...       ...       ...  ...         ...         ...         ...\n",
              "23995      4         0         0  ...           0           0           0\n",
              "23996      1         0         0  ...           0           0           0\n",
              "23997      2         0         0  ...           0           0           0\n",
              "23998      3         0         0  ...           0           0           0\n",
              "23999      4         0         0  ...           0           0           0\n",
              "\n",
              "[24000 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the feature and target column\n",
        "y = sample_data.pop('label')\n",
        "X = sample_data\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRaN4RAYGDiI",
        "outputId": "47bdd70b-9201-40dc-8cec-d2a40fe1908f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       feature0  feature1  feature2  ...  feature781  feature782  feature783\n",
            "0             0         0         0  ...           0           0           0\n",
            "1             0         0         0  ...           0           0           0\n",
            "2             0         0         0  ...           0           0           0\n",
            "3             0         0         0  ...           0           0           0\n",
            "4             0         0         0  ...           0           0           0\n",
            "...         ...       ...       ...  ...         ...         ...         ...\n",
            "23995         0         0         0  ...           0           0           0\n",
            "23996         0         0         0  ...           0           0           0\n",
            "23997         0         0         0  ...           0           0           0\n",
            "23998         0         0         0  ...           0           0           0\n",
            "23999         0         0         0  ...           0           0           0\n",
            "\n",
            "[24000 rows x 784 columns]\n",
            "0        1\n",
            "1        2\n",
            "2        3\n",
            "3        4\n",
            "4        1\n",
            "        ..\n",
            "23995    4\n",
            "23996    1\n",
            "23997    2\n",
            "23998    3\n",
            "23999    4\n",
            "Name: label, Length: 24000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will use the sklearn train_test_split which shuffle and break the data ins required ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "# split into train test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
        "print('Train data feature: ', X_train)\n",
        "print('Train data Label: ', y_train)\n",
        "print('Test data feature: ', X_test)\n",
        "print('Test data Label: ',y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ_S9ZT8DFhi",
        "outputId": "e04ed628-b961-4f41-cf3c-7fe4aba8cf52"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data feature:         feature0  feature1  feature2  ...  feature781  feature782  feature783\n",
            "18816         0         0         0  ...           0           0           0\n",
            "11103         0         0         0  ...           0           0           0\n",
            "2178          0         0         0  ...           0           0           0\n",
            "9460          0         0         0  ...           0           0           0\n",
            "18921         0         0         0  ...           0           0           0\n",
            "...         ...       ...       ...  ...         ...         ...         ...\n",
            "8429          0         0         0  ...           0           0           0\n",
            "5552          0         0         0  ...           0           0           0\n",
            "20339         0         0         0  ...           0           0           0\n",
            "13200         0         0         0  ...           0           0           0\n",
            "15549         0         0         0  ...           0           0           0\n",
            "\n",
            "[19200 rows x 784 columns]\n",
            "Train data Label:  18816    1\n",
            "11103    4\n",
            "2178     3\n",
            "9460     1\n",
            "18921    2\n",
            "        ..\n",
            "8429     2\n",
            "5552     1\n",
            "20339    4\n",
            "13200    1\n",
            "15549    2\n",
            "Name: label, Length: 19200, dtype: int64\n",
            "Test data feature:         feature0  feature1  feature2  ...  feature781  feature782  feature783\n",
            "2977          0         0         0  ...           0           0           0\n",
            "1820          0         0         0  ...           0           0           0\n",
            "11610         0         0         0  ...           0           0           0\n",
            "2534          0         0         0  ...           0           0           0\n",
            "15614         0         0         0  ...           0           0           0\n",
            "...         ...       ...       ...  ...         ...         ...         ...\n",
            "16511         0         0         0  ...           0           0           0\n",
            "16850         0         0         0  ...           0           0           0\n",
            "806           0         0         0  ...           0           0           0\n",
            "4312          0         0         0  ...           0           0           0\n",
            "4686          0         0         0  ...           0           0           0\n",
            "\n",
            "[4800 rows x 784 columns]\n",
            "Test data Label:  2977     2\n",
            "1820     1\n",
            "11610    3\n",
            "2534     3\n",
            "15614    3\n",
            "        ..\n",
            "16511    4\n",
            "16850    3\n",
            "806      3\n",
            "4312     1\n",
            "4686     3\n",
            "Name: label, Length: 4800, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of Train data feature: ', X_train.shape , type(X_train))\n",
        "print('Shape of Train data Label: ', y_train.shape , type(y_train))\n",
        "print('Shape of Test data feature: ', X_test.shape)\n",
        "print('Shape of Test data Label: ',y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCCyJV5WOMyF",
        "outputId": "334650c2-ba34-4a15-cff9-a11c127c6a2f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Train data feature:  (19200, 784) <class 'pandas.core.frame.DataFrame'>\n",
            "Shape of Train data Label:  (19200,) <class 'pandas.core.series.Series'>\n",
            "Shape of Test data feature:  (4800, 784)\n",
            "Shape of Test data Label:  (4800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the unique lable from train and test feature and see if we dont have class imbalance in train and test data\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print('Train label:\\n', np.asarray((unique, counts)).T)\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print('Test Label:\\n',np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "id": "njpnrickSNAw",
        "outputId": "3e12d3df-4e94-4c86-aa72-3526991b043d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label:\n",
            " [[   1 4807]\n",
            " [   2 4777]\n",
            " [   3 4832]\n",
            " [   4 4784]]\n",
            "Test Label:\n",
            " [[   1 1193]\n",
            " [   2 1223]\n",
            " [   3 1168]\n",
            " [   4 1216]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating some common function\n",
        "#Creating Function for plotting the confusion Matrix\n",
        "def plot_confusion_matrix(p_y_train, p_y_train_predictions, p_y_test, p_y_test_predictions):\n",
        "          \n",
        "    #Lets Calculate the confusion Matrix\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    train_conf_matrix = confusion_matrix(p_y_train,p_y_train_predictions)\n",
        "    test_conf_matrix = confusion_matrix(p_y_test,p_y_test_predictions)\n",
        "    print( \"Train confusion matrix: \\n\", train_conf_matrix)\n",
        "    print(\"Test confusion matrix: \\n\", test_conf_matrix)\n",
        "    \n",
        "    #Plotting the confusion matrix for better interpretation\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, axes = plt.subplots(ncols=2, figsize=(8, 3))\n",
        "    ax1, ax2 = axes\n",
        "    sns.heatmap(train_conf_matrix, annot=True, fmt='g', ax=ax1)\n",
        "    sns.heatmap(test_conf_matrix, annot=True, fmt='g', ax=ax2)\n",
        "    ax1.set_title('Train Data')\n",
        "    ax1.xaxis.set_ticklabels(['0', '1'])\n",
        "    ax1.yaxis.set_ticklabels(['0', '1'])\n",
        "    ax2.set_title('Test Data')\n",
        "    ax2.xaxis.set_ticklabels(['0', '1'])\n",
        "    ax2.yaxis.set_ticklabels(['0', '1'])\n",
        "    fig.suptitle('Confusion Matrix')\n",
        "\n",
        "def print_classification_report(p_y_train, p_y_train_predictions, p_y_test, p_y_test_predictions):\n",
        "    from sklearn.metrics import classification_report\n",
        "    train_class_rpt = classification_report(p_y_train, p_y_train_predictions)\n",
        "    print(\"======================================================\")\n",
        "    print(\"Train Classification Report:\")\n",
        "    print(train_class_rpt)\n",
        "    print(\"======================================================\")\n",
        "    test_class_rpt = classification_report(p_y_test, p_y_test_predictions)\n",
        "    print(\"Test Classification Report:\")\n",
        "    print(test_class_rpt)\n",
        "    print(\"======================================================\")"
      ],
      "metadata": {
        "id": "xlgk8Ovi6oDW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q3.b Train a multi-layer perceptron (MLP)**"
      ],
      "metadata": {
        "id": "7eZaFyrF4iyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.b : [C, R] Use the train partition to train a multi-layer perceptron (MLP) with an input layer, 3\n",
        "hidden layers and an output layer. You are free to choose the number of neurons and their ac-\n",
        "tivation functions in the hidden layers. Use a soft-max at the output layer and a cross-entropy\n",
        "loss function to perform classifcation. Describe the MLP architecture you have used. Using the\n",
        "MLP model, report the accuracy, precision, recall, F1 score for the train set and test set."
      ],
      "metadata": {
        "id": "StmTDJ3L4iyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import preprocessing\n",
        "# from keras.models import sequential #forward Propogation\n",
        "# from keras.layers import Dense , Dropout, BatchNormalization #Dense is used for creating hidden and input layers\n",
        "# from keras import optimizers # for back propogation\n",
        "# #converting y response variable into categorical.\n",
        "# from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import  classification_report , confusion_matrix , accuracy_score"
      ],
      "metadata": {
        "id": "14YbxqNyYToI"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ],
      "metadata": {
        "id": "LGITdWRy_Z2b"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the label data into categorical data\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "ek9JJR8oZzSw"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of Train data feature: ', X_train.shape , 'type: ', type(X_train))\n",
        "print('Shape of Train data Label: ', y_train.shape , 'type: ', type(y_train))\n",
        "print('Shape of Test data feature: ', X_test.shape , 'type: ', type(X_test))\n",
        "print('Shape of Test data Label: ',y_test.shape , 'type: ', type(y_test))\n",
        "#Looking at the shape , we have 784 input and 5 output.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGCYj_pCcVz7",
        "outputId": "8ba1c319-0275-46d1-a819-fd093f9603fc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Train data feature:  (19200, 784) type:  <class 'numpy.ndarray'>\n",
            "Shape of Train data Label:  (19200, 5) type:  <class 'numpy.ndarray'>\n",
            "Shape of Test data feature:  (4800, 784) type:  <class 'numpy.ndarray'>\n",
            "Shape of Test data Label:  (4800, 5) type:  <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create NN layers now\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(10,input_dim=784,activation='relu')) #i/p Layer\n",
        "model.add(layers.Dense(8,input_dim=10,activation='relu')) # hidden layer1\n",
        "model.add(layers.Dense(5,input_dim=8,activation='relu')) # hidden layer2\n",
        "model.add(layers.Dense(5,input_dim=5,activation='relu')) # hidden layer3\n",
        "model.add(layers.Dense(5,activation='softmax')) #output layer\n",
        "\n"
      ],
      "metadata": {
        "id": "FSrET04ceR7X"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model.layers)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqdh1I8UeSCq",
        "outputId": "ca1c3818-8f55-4a53-d761-b318373d2964"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NF-PyoU-l3bU"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forward and back ward propogration\n",
        "model.fit(X_train, y_train, batch_size=100, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkMUPtmom3ru",
        "outputId": "fcf51747-62c1-44f0-a6cb-78be0595a667"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "192/192 [==============================] - 1s 4ms/step - loss: 1.6838 - accuracy: 0.3379\n",
            "Epoch 2/100\n",
            "192/192 [==============================] - 1s 4ms/step - loss: 1.1212 - accuracy: 0.4873\n",
            "Epoch 3/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.8794 - accuracy: 0.6359\n",
            "Epoch 4/100\n",
            "192/192 [==============================] - 1s 5ms/step - loss: 0.7366 - accuracy: 0.6901\n",
            "Epoch 5/100\n",
            "192/192 [==============================] - 1s 5ms/step - loss: 0.6658 - accuracy: 0.7011\n",
            "Epoch 6/100\n",
            "192/192 [==============================] - 1s 4ms/step - loss: 0.6103 - accuracy: 0.7112\n",
            "Epoch 7/100\n",
            "192/192 [==============================] - 1s 4ms/step - loss: 0.5785 - accuracy: 0.7139\n",
            "Epoch 8/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7188\n",
            "Epoch 9/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7236\n",
            "Epoch 10/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7238\n",
            "Epoch 11/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.4682 - accuracy: 0.7419\n",
            "Epoch 12/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.7682\n",
            "Epoch 13/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.3566 - accuracy: 0.8969\n",
            "Epoch 14/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9436\n",
            "Epoch 15/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9580\n",
            "Epoch 16/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9640\n",
            "Epoch 17/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9683\n",
            "Epoch 18/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.1210 - accuracy: 0.9754\n",
            "Epoch 19/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9782\n",
            "Epoch 20/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9801\n",
            "Epoch 21/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9812\n",
            "Epoch 22/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0834 - accuracy: 0.9817\n",
            "Epoch 23/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9836\n",
            "Epoch 24/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9845\n",
            "Epoch 25/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9864\n",
            "Epoch 26/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9866\n",
            "Epoch 27/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0585 - accuracy: 0.9860\n",
            "Epoch 28/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9878\n",
            "Epoch 29/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9877\n",
            "Epoch 30/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9892\n",
            "Epoch 31/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9897\n",
            "Epoch 32/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9876\n",
            "Epoch 33/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9894\n",
            "Epoch 34/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9914\n",
            "Epoch 35/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9920\n",
            "Epoch 36/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9917\n",
            "Epoch 37/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9908\n",
            "Epoch 38/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9906\n",
            "Epoch 39/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9908\n",
            "Epoch 40/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9929\n",
            "Epoch 41/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9928\n",
            "Epoch 42/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9940\n",
            "Epoch 43/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9921\n",
            "Epoch 44/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9939\n",
            "Epoch 45/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9916\n",
            "Epoch 46/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9945\n",
            "Epoch 47/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9949\n",
            "Epoch 48/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9948\n",
            "Epoch 49/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9954\n",
            "Epoch 50/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9953\n",
            "Epoch 51/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9940\n",
            "Epoch 52/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9936\n",
            "Epoch 53/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9941\n",
            "Epoch 54/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9958\n",
            "Epoch 55/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9968\n",
            "Epoch 56/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9964\n",
            "Epoch 57/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9965\n",
            "Epoch 58/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9968\n",
            "Epoch 59/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9929\n",
            "Epoch 60/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9933\n",
            "Epoch 61/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9938\n",
            "Epoch 62/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9942\n",
            "Epoch 63/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9962\n",
            "Epoch 64/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9966\n",
            "Epoch 65/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9956\n",
            "Epoch 66/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9972\n",
            "Epoch 67/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9963\n",
            "Epoch 68/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9955\n",
            "Epoch 69/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9964\n",
            "Epoch 70/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9957\n",
            "Epoch 71/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9944\n",
            "Epoch 72/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9953\n",
            "Epoch 73/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9961\n",
            "Epoch 74/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9959\n",
            "Epoch 75/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9955\n",
            "Epoch 76/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9974\n",
            "Epoch 77/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9972\n",
            "Epoch 78/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0128 - accuracy: 0.9976\n",
            "Epoch 79/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9978\n",
            "Epoch 80/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0155 - accuracy: 0.9971\n",
            "Epoch 81/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9946\n",
            "Epoch 82/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9923\n",
            "Epoch 83/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9956\n",
            "Epoch 84/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9970\n",
            "Epoch 85/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9969\n",
            "Epoch 86/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9968\n",
            "Epoch 87/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9967\n",
            "Epoch 88/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0137 - accuracy: 0.9971\n",
            "Epoch 89/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9972\n",
            "Epoch 90/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9973\n",
            "Epoch 91/100\n",
            "192/192 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9954\n",
            "Epoch 92/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9961\n",
            "Epoch 93/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9972\n",
            "Epoch 94/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9966\n",
            "Epoch 95/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9959\n",
            "Epoch 96/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9953\n",
            "Epoch 97/100\n",
            "192/192 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9966\n",
            "Epoch 98/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9971\n",
            "Epoch 99/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9975\n",
            "Epoch 100/100\n",
            "192/192 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9979\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe03e9eeb10>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted values\n",
        "y_train_predict = model.predict(X_train)\n",
        "y_train_predict=np.argmax(y_train_predict, axis=1)\n",
        "y_train_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOa-V1k3ofBJ",
        "outputId": "238ad8a2-1c56-4a03-9796-05a35407908f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 3, ..., 4, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predict = model.predict(X_test)\n",
        "y_test_predict=np.argmax(y_test_predict, axis=1)\n",
        "y_test_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqfpn63Dotn7",
        "outputId": "6741cf37-e277-4d01-f5ff-4ffca1abe37d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, ..., 3, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=np.argmax(y_test, axis=1)\n",
        "y_train=np.argmax(y_train, axis=1)"
      ],
      "metadata": {
        "id": "I1IZdllHEihu"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make class predictions with the model\n",
        "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        "\tprint(( predictions[i], y_test[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3IaVzzri1H2",
        "outputId": "3d740968-04f5-4987-fb85-197bf4ab5c91"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2)\n",
            "(1, 1)\n",
            "(2, 3)\n",
            "(3, 3)\n",
            "(3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MLP Statistics: \\n')\n",
        "print_classification_report(y_train,y_train_predict,y_test,y_test_predict)\n",
        "plot_confusion_matrix(y_train,y_train_predict,y_test,y_test_predict)"
      ],
      "metadata": {
        "id": "pYWGHF6t8YD7",
        "outputId": "673e6134-3c22-4fdd-c0a4-33662676578d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Statistics: \n",
            "\n",
            "======================================================\n",
            "Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      4807\n",
            "           2       1.00      1.00      1.00      4777\n",
            "           3       1.00      1.00      1.00      4832\n",
            "           4       1.00      1.00      1.00      4784\n",
            "\n",
            "    accuracy                           1.00     19200\n",
            "   macro avg       1.00      1.00      1.00     19200\n",
            "weighted avg       1.00      1.00      1.00     19200\n",
            "\n",
            "======================================================\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.97      0.97      1193\n",
            "           2       0.96      0.97      0.96      1223\n",
            "           3       0.96      0.95      0.95      1168\n",
            "           4       0.99      0.99      0.99      1216\n",
            "\n",
            "    accuracy                           0.97      4800\n",
            "   macro avg       0.97      0.97      0.97      4800\n",
            "weighted avg       0.97      0.97      0.97      4800\n",
            "\n",
            "======================================================\n",
            "Train confusion matrix: \n",
            " [[4804    0    3    0]\n",
            " [   3 4761   12    1]\n",
            " [  14    1 4817    0]\n",
            " [   2    3    5 4774]]\n",
            "Test confusion matrix: \n",
            " [[1161    8   22    2]\n",
            " [   5 1183   25   10]\n",
            " [  21   34 1112    1]\n",
            " [   3   11    2 1200]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x216 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **===========================================================**"
      ],
      "metadata": {
        "id": "RRkZorf0NXZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 (c) [C, R] Now consider that each data point represented in vector form can be represented as a\n",
        "p \u0002 p matrix for a suitable p. Using this transformed train data, build a convolution neural\n",
        "network (CNN) with 3 convolution cum max-pool blocks (where max-pool follows a convolu-\n",
        "tion operation) followed by a fully connected layer and an output layer. You are free to choose\n",
        "the kernel size, stride and padding in each convolution operation. Also use a max-pool layer\n",
        "of appropriate grid size in each layer. Use a soft-max at the output layer and a cross-entropy\n",
        "loss function to perform classification. Describe the CNN architecture you have used. Using the\n",
        "CNN model, report the accuracy, precision, recall, F1 score for the train set and test set."
      ],
      "metadata": {
        "id": "yqJcj5yWGvUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imort the required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import  classification_report , confusion_matrix , accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd #the pandas library is useful for data processing \n",
        "import numpy as np\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "Ih_FW-cI10Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the data from the csv file \n",
        "sample_data_cnn = pd.read_csv('https://github.com/arvind-maurya/MachineLearning/blob/master/Assignment/Q3/Q3_data.csv?raw=true', index_col=False)\n",
        "#print the data \n",
        "sample_data_cnn"
      ],
      "metadata": {
        "id": "aVq5tnDJuXWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the feature and target column\n",
        "y_cnn = sample_data_cnn.pop('label')\n",
        "X_cnn = sample_data_cnn\n",
        "X_cnn = X_cnn.to_numpy()\n",
        "y_cnn = y_cnn.to_numpy()\n",
        "print(X_cnn)\n",
        "print(y_cnn)"
      ],
      "metadata": {
        "id": "UsTIWr1uuXWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will use the sklearn train_test_split which shuffle and break the data ins required ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "# split into train test sets\n",
        "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn,y_cnn, test_size=0.2)\n",
        "X_train_cnn = X_train_cnn/255\n",
        "X_test_cnn = X_test_cnn/255\n",
        "print('Train data feature: ', X_train_cnn)\n",
        "print('Train data Label: ', y_train_cnn)\n",
        "print('Test data feature: ', X_test_cnn)\n",
        "print('Test data Label: ',y_test_cnn)"
      ],
      "metadata": {
        "id": "F8E2gCJPuXWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of Train data feature: ', X_train_cnn.shape)\n",
        "print('Shape of Train data Label: ', y_train_cnn.shape)\n",
        "print('Shape of Test data feature: ', X_test_cnn.shape)\n",
        "print('Shape of Test data Label: ',y_test_cnn.shape)"
      ],
      "metadata": {
        "id": "ODny2mnCuXWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the unique lable from train and test feature and see if we dont have class imbalance in train and test data\n",
        "unique, counts = np.unique(y_train_cnn, return_counts=True)\n",
        "print('Train label:\\n', np.asarray((unique, counts)).T)\n",
        "unique, counts = np.unique(y_test_cnn, return_counts=True)\n",
        "print('Test Label:\\n',np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "id": "_6Z4_NV0uXWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rehaping the images into equal dim.\n",
        "X_train_cnn = X_train_cnn.reshape(len(X_train_cnn),28,28,1)\n",
        "X_test_cnn = X_test_cnn.reshape(len(X_test_cnn),28,28,1)"
      ],
      "metadata": {
        "id": "jIWGib9AxOgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "#one-hot encode target column\n",
        "y_train_cnn = to_categorical(y_train_cnn)\n",
        "y_test_cnn = to_categorical(y_test_cnn)\n",
        "y_train_cnn[0]"
      ],
      "metadata": {
        "id": "yjHuoTip8h2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model\n",
        "model_cnn = keras.Sequential()\n",
        "#add model layers\n",
        "model_cnn.add(layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model_cnn.add(layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model_cnn.add(layers.Conv2D(16, kernel_size=3, activation='relu'))\n",
        "model_cnn.add(layers.MaxPooling2D(pool_size=2))\n",
        "model_cnn.add(layers.Flatten())\n",
        "model_cnn.add(layers.Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "zx7YIQbR-i6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "78I-syPI-wYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, validation_data=(X_test_cnn, y_test_cnn), epochs=3)"
      ],
      "metadata": {
        "id": "5ziME6Do_VJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict first 4 images in the test set\n",
        "model_cnn.predict(X_test_cnn[:4])"
      ],
      "metadata": {
        "id": "MTqyrMLPCczq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above give the probability for prediction for classes. We should take the value which has higher probability "
      ],
      "metadata": {
        "id": "_IQhOA1DDCXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#actual results for first 4 images in test set\n",
        "y_test_cnn[:4]"
      ],
      "metadata": {
        "id": "zX8fQJI3Ckiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model_cnn.evaluate(X_test_cnn, y_test_cnn, verbose = 0 )\n",
        "print(\"Test Score: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])"
      ],
      "metadata": {
        "id": "KbRpcs-tyHU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same  is matching with the test data output of test data."
      ],
      "metadata": {
        "id": "BFrCBOEkDR_l"
      }
    }
  ]
}